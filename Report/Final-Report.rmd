---
title: "Health Economic Modelling: Final Report"
subtitle: "Group 4"
author: "Alex Bujorianu (s2451980) & Rusheel Mehra(s2344211)"
date: "01/04/2021"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- Front Page -->
\newpage

```{r, include=FALSE}
load("../Part_2/PSA-sim-environment.RData")
```


# Process Description & DES Design

"Describe and motivate the choices you made during data analysis steps, design of the DES model, the simulation results, and the interpretation of these results."
**Simulation model**:
We begin the process by building a simple simulation model of the best standard care. The best standard care (BSC) is the clinical pathway as studied in the clinical trial as seen in figure 1. 
After diagnosis, the patient enters the first line of treatment, henceforth referred to as Tx1. In Tx1, the patient has to undergo 5 treatment cycles. The patient can follow 5 trajectories within this line of treatment. The first is when the patient has no complications and completes a full cycle. In this event the patient proceeds to the next cycle. The second trajectory is when a patient dies during a cycle. In such an event, the patient exits the system. The third trajectory is when a patient has a major complication. In this event, the patient exits Tx1 but continues into the first follow up and then through the rest of the pathway. So, in essence, if a patient experiences major complications, they are treated as they have completed all 5 cycles of the treatment line. THe fourth trajectory is when the patient experiences minor complications. Minor complications add health and economic burden but do not affect the patient's path through the system. The last trajectory is that  of a patient that has completed all the cycles of a treatment line. 
The patients who survived Tx1 move on to the follow up period.  In the follow up, the patient follows two possible trajectories, one where they live and one where they die. The patients who die in the follow up exit the system. 
After the first follow up, the remaining surviving patients enter the second treatment line, referred to as Tx2. Tx2 and the trajectories within it are identical to Tx1 and it's trajectories. The patients surviving after Tx2 go in to the final phase of the pathway, the second follow up, also known as palliative care. This last phase lasts for a fixed duration or till the patient dies, whichever is sooner.

```{r, echo=FALSE}
knitr::include_graphics("clinical-pathway.png", error = FALSE)
```


First, we modeled the current treatment strategy as the control strategy.

The base-case analysis (BCA) does not consider uncertainty in the model parameters, though it may reflect patient-level variation in models (i.e. stochastic uncertainty or first-order uncertainty).

The probabilistic sensitivity analysis (PSA) also accounts for parameter uncertainty (i.e., second-order uncertainty).

# Cost-effectiveness Estimation of the Novel Diagnostic Tests

# Interpretation of the Results

# Feedback provided

The feedback we gave really focused on code quality and reproducibility. One of the most common mistakes we see (and which you, the teachers, should have discouraged) is the use of setwd(). Using this function means the code will only run on the programmer’s PC and no on else’s. We recommended setting relative paths inside the root directory instead. Another mistake the group made was having the distribution fitting done inside the simulation files instead of separately. When we found a mistake, they had to make the changes in multiple places.

Also, we recommended that they use git to manage their source code, as they had to send us 2 different versions of their PSA simulation after we received it. 

Lastly, we commented on programming best practices—for example, using helper functions, nested if statements to simplify conditional expressions, and so on.  

# Feedback received

We will go through the feedback received in a line-by-line fashion and describe how we changed our code (or chose not to change it) based on the feedback.

> To introduce the reader to the code, it is a good suggestion to give the names of the sections that can be found in the further part of the code and add more pseudo-code. If you use different files for the different parts (e.g. data analysis, functions), it might help to add some code that describes what the file contains and where it is used for. Now some functions are provided in the main PSA code, and others are in a separate file. It would increase clarity and transparency.

We agreed with this and renamed some of the files to more descriptive names. We provided an explanation of what the code does in the README file.

> Also, you have 4 events in your trajectory, but for the event minor complication, there is no time to event defined in your Tx1.time function.

In the assignment instructions it said that patients continue the treatment cycle if they experience only minor complications. We understood that each treatment cycle was fixed at 30 days.

> Last, you assume the time to a major complication in Tx2 is symmetrical to TX1.

We do indeed assume this, because we were instructed to, and we had limited time to do more distribution fitting. We could easily improve this in the model by changing the Tx2.Time function.

> You give a normal distribution for your costs. However, for the distribution of costs, use a log-normal or gamma distribution, as costs cannot be negative (and a normal distribution can give you a negative number as a result)

This is a valid point. But it is very unlikely that those distributions would return a negative cost because they have a large mean. We used the normal distribution because it is more straightforward to implement. Also, we are not sure if a gamma distribution is appropriate for most of the costs, as they are not meant to be skewed.

> for example in the following code line of the function func.exp.costs you wrote this line: 
total_cost <- total_cost + ((Tx1.Cycles+1) * (278+256+194)) + ((Tx2.Cycles+1) * (278+256+194))

We are doing this only in the BCA simulation because that is for patient-level uncertainty, not parameter uncertainty. The PSA simulation uses functions to reflect uncertainties.

> [If] you want to have a look at it again in a few years, it is easier if you can directly read what each function is doing. This holds for a general introduction of the formula but also within the formula, as described in the example below: 

> An example is that for the function: Func.tx1cost you use the input parameter Tx1.complications. You created an If-statement with Tx1.complications ==1 , but it would be more readable if you can directly see what the 1 suggests, is it a minor or major complication.

We do comment our code in various places to explain what events the numbers refer to. In the future, we would consider returning strings with (at least some of) the functions, in which case this would be self-explanatory.

> For example in Tx1.Event you still use the previously defined probability of 3% of event death occurring. A suggestion is to fit a logistic regression model, to predict this probability of death (event ==1 in the data), based on sex and age of the patient. 

We chose not to use the results of our logistic regression in determining the probability because neither of the two predictors (age and sex) were significant at the α = 0.10 level, which is the weakest threshold of statistical significance accepted by the scientific community. (Most journals would prefer to see a p value less than 5% in order to declare it “significant”). As you can see from our logistic regression results, neither predictor meets that criteria:

```{r}
summary(logreg_death)
```
Even though we had more than 500 observations, only 31 people died in those two cycles. It is well-known that binomial events with a low probability are difficult to test statistically and require a very large number of observations. A good example is vaccination: clinical trials with thousands of participants still do not find rare complications that emerge only once the vaccine has been administered to the general population. This happened with the 1976 swine flu vaccine, which caused a 1 per 100,000 increase in Guillain Barré syndrome [1]. More recently there is controversy that the AstraZeneca vaccine can (rarely) cause blood clots. 

Additionally, implementing this would have lead to more code, which is an additional source of bugs and errors. 

>You did not implement this function in your exp trajectory in any way. So you don’t use the function and patients still continue treatment, even though they don’t respond.

This is simply incorrect. The exp.model uses the function Tx1.Event.alt which skips the additional treatment cycles if the helper function returns false.

>However, you create three functions  (func.dx1cost, func.dx2cost and func.dx3cost) to incorporate uncertainties of costs for the diagnostic tests. These functions are never used again or implemented in your trajectory. 

They are. The exp model uses function.exp.costs which calls up the func.dxcost helper functions.


# Overall reflection

**Approach to the assignment**: We took a really programmatic approach to this assignment, which served us well for the most part. Alex is an MBIT student who has done the software development course, and it was his idea to use git for the project; to test functions separately; and to try and write modular code. However, we found R extremely frustrating to use for serious programming. We didn’t know how to do unit tests in R. Basic data structures (like recursive lists) were missing. Print statements inside functions or trajectories didn’t seem to print when the model was executed. Finally, the error messages were really unhelpful because they didn’t even have a line number! Using break points didn’t help either; in fact, they seemed to have no effect until after the simulation had already run into errors.

**Collaboration in pairs**: this was fine. We tried to divvy up the work as best we could. The branch functionality of git came in very handy at times.

**Challenges encountered**: Neither of us were very experienced with R and even less so with simmer. We had to learn about a lot of peculiarities, like the clusterExport function; how to save data from the PSA simulation (which took as a while to figure out); how various functions worked; how to append to vectors (copy-on-write is weird); and even the indexing in R is very strange. It uses commas to index rows or columns. The indexing for recursive data structures is bizarre: we do not see why it has to be list_of_lists[[1]][1] instead of just list_of_lists[1][1] like you can do in Java with arrays.

**What we learned from this course**: How to do DES simulation in R; how to fit distributions in R; how to do statistical programming in general. We also learned a lot about the theory of health simulation, though this didn’t come up so much in the practical assignment. The inclusion of economics was a nice touch. We would have liked it if the advanced topics were covered in a bit more detail; the lesson we had on meta-modelling and simulation optimisation felt rushed—there wasn’t enough time in one or two lessons to fully absorb that material. 

Moreover, we would also really have appreciated some more *programming* guidance. A lot of the people doing this course don’t have a formal background in software development; they don’t know about unit testing, functional programming paradigms, types and data structures in R, etc. It would have helped if you guys could have covered debugging in more detail—there were times when we really got stuck on those extremely unhelpful error messages.

**Our view on applying DES for health economic evaluations**: It’s complicated. One thing that’s clear to us is that you need good quality clinical trials with lots of data, in order to fit distributions and have accurate parameters. Furthermore, as your case study on meta-modelling showed us, the model is only as good as its underlying data. You can’t just extrapolate to a group, e.g. aneurysm screening in under 40s, based purely on simulation results. 

Speaking of meta-modelling, it is our personal opinion that if you need a meta-model in the first place, your original model is probably too complex to begin with. We think the real reason meta-models perform well is because simpler models are sufficient; trying to capture 10% more real-life complexity can lead to 10x the computational burden (not to mention code complexity). More sophisticated models could just be kept around for validation purposes. 

Also, as a programmer, Alex would find it hard to trust a health economic model if the codebase is really messy. A simpler bug-free model is better than a more complex model filled with bugs.

# References
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="https://doi.org/10.1002/ana.410090707">1</a>]
</td>
<td class="bibtexitem">
Lawrence&nbsp;B. Schonberger, Eugene&nbsp;S. Hurwitz, Peter Katona, Robert&nbsp;C. Holman, and
  Dennis&nbsp;J. Bregman.
 Guillain-barré syndrome: Its epidemiology and associations with
  influenza vaccination.
 <em>Annals of Neurology</em>, 9(S1):31--38, 1981.
[&nbsp;<a href="https://doi.org/10.1002/ana.410090707">DOI</a>&nbsp;| 
<a href="http://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1002/ana.410090707">arXiv</a>&nbsp;| 
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ana.410090707">http</a>&nbsp;]

</td>
</tr>
</table>

